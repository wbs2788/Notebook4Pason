# **机器学习**

## 机器学习绪论

### 现象总结

#### 传统机器学习算法

NN，SVM，Adaboost

SGD、学习策略

#### 深度学习

模型选择参数化，结构手工调整及优化。神经网络结构搜索，模型选择自动化

#### 机器学习理论

![image-20211211210005238](C:\Users\surafce book2\AppData\Roaming\Typora\typora-user-images\image-20211211210005238.png)

#### 发展趋势

普适机器学习：基础方法、广泛应用（集成学习）

挑战：

- 泛化能力：学习推广能力。SVM：理论到实践；EL（极限学习机）：实践到理论
- 学习速度：“训练速度”与“测试速度”的平衡。
- 可理解性

发展：

- 未标记数据处理
- 代价敏感：如何评价正确当成错误和错误当成正确
- 高维数据处理：属性多
- 结构数据学习：挖掘“结构”
- 领域知识利用：特定领域的“最优学习器”

### 机器学习系统结构

学习算法定义：给定算法$A$、任务$T$、性能评估量$P$、经验$E$，当$A$对$T$进行操作时，如果$A$随$E$的增加使得$P$完善，则称$A$具有从$E$学习的能力。

训练经验$E$：为$P$提供直接或间接反馈，学习器控制训练顺序的能力。

选择目标函数：

- 知识表达：对状态空间的描述
- 目标函数$V(x)=w^T\bar x$，$\bar x$表示$x$的增广。
- 选择函数逼近算法：估计训练值。

调整权值：最小二乘、最小均方

机器学习——假设空间搜索

解决的问题：特定数据$\to$学习$\to$一般目标函数。数据充分$\to$条件？$\to$算法收敛到目标函数。

## 机器学习研究进展

### 机器学习研究变迁

- 连接主义：统计机器学习、集成机器学习
- 符号主义：符号机器学习
- 行为主义：增强机器学习

#### 统计机器学习

Dietterich将感知机类的连接机器学习分离出来，并根据划分机理，将其分为两种类型： 统计机器学习与集成机器学习。这意味着， 感知机类机器学习是重点。

强调：

- 表示：非线性问题的线性表示
- 泛化：以泛化能力为基础的算法设计

#### 增强学习

“适应性”是控制理论中最重要的概念之一，以往在计算机科学中考虑较少。遗传学习最终成为实现增强机器学习的一种方法

#### 符号机器学习

改变泛化目标为符号描述(数据挖掘)。这意味着，符号机器学习已不是与统计机器学习竞争的研究，而是一个研究目标与其不同的研究范式。

#### 分析机器学习被放弃

要求过高，说明从表示到学习均需要考虑新的理论基础。

#### 发展动向

真实世界的问题十分困难，现有的理论、方法，甚至理念已不能满足需要，由此，大量近代数学的研究结果被引入计算机科学，由此，形成新的机器学习范式。

### 统计机器学习

研究集中在：

- 表示问题：非线性问题的线性表示
- 泛化问题：对给定的样本集合，通过算法建立模型，对问题世界为真的程度

#### 线性表示

意义

- 计算：一般非线性算法是 $\mathcal{NP}-\mathrm{complete}$ 的。
- 认识世界：**只有在某个空间中可以描述为线性的世界，人们才说，这个世界已被认识**(将问题变换为另一个问题）
- 数学方法：寻找一个映射，将非线性问题映射到线性空间，以便其可以线性表示。

#### 机器学习中寻找线性空间的方法

1. 整体线性，Hilbert 空间（核映射）
2. 类似分段线性，Madaline 或弱分类方法。

Hilbert 空间：具有一般意义的线性内积空间，在机器学习中构成特征空间。

#### 线性不可分问题

将线性不可分问题变为线性可分问题关键是寻找映射，将样本集映射到特征空间，使其在特征空间线性可分。

如何选择特征空间基？

一般可用多项式或三角函数基，但是寻找一般的方法描述特征空间导致维数灾难。

与神经网络相比，核函数的选择可以借助领域知识。

那么可以不显式地描述空间，将特征空间上的描述转为样本空间上的描述，即核方法。

#### 泛化能力描述

PAC 界、VC 维界、最大边缘

##### 最大边缘

衡量分类器性能的一个指标
$$
err(h) \le \sqrt {\frac c l \left(\frac {R^2} {M^2} \log^2l-\log \delta\right)}
$$
边缘最大，误差最小，泛化能力越强。

#### 研究趋势

- 泛化不等式需要样本集 i.i.d 能不能放宽
- 如何根据领域需求选择核函数

### 集成学习

#### 来源

- 神经科学：Hebb 学习规则
- 数学方法：非线性问题分段化
- 计算技术：Widrow 的 Madaline 模型
- 统计理论： PAC 弱可学习理论

##### Madaline

本质是放弃感知机对样本空间划分的超平面需要满足连续且光滑的条件，代之分段的超平面。

##### Schaphire 理论

**如果一个概念是弱可学习的，充要条件是它是强可学习的**

意味多个弱分类器可以集成为一个强分类器。

#### 问题

- 泛化能力的估计还存在问题
- 理论研究还基于观察和积累，大量现象不可解释。

### 符号机器学习

符号机器学习划分样本集合的等价关系是学习所得，学习只是在这个等价关系下约简样本集合。

#### 问题

一个无矛盾规则越短，其覆盖对象越多，因此，符号机器学习的泛化是以信息长度描述的。这样，“最小” 树或规则集合就是其目标函数

这样有两个因素影响这个目标：

- 从实数域到符号域的映射
- 在符号域上的约减

显然都是 $\mathcal{NP}-\mathrm{complete}$ 的。

**但是，只有在符号域上的约减是符号机器学习特有，因此其泛化能力受到限制。**

#### 特点

这类机器学习主要处理符号，因此，如果获得一个长度较短的数据集合的描述，可以将其翻译为人可以阅读的文本。人通过阅读这个 文本就可以了解数据集合的内容。

这个目标与泛化能力无关，计算结果只是给定数据集合根据特定需求的一个可以被人阅读的缩影。这与传统数据分析的目标一致。

## AlphaGo

### 博弈树搜索

适用于具有完全信息的二人零和有限确定性博弈。

传统博弈树搜索：基于 Alpha-beta 剪枝的极小极大算法

#### 极小极大算法

根据最佳策略确定最佳可实现收益。

一方在可选的选项中选择其优势最大化的选择，另一方选择令对手优势最小化的方法。

性质：

- 完整性
- 最优性
- $O(b^m)$
- 限制性（不一定能遍历整棵树，时间限制）
- 关键改进：利用评估函数

####  Alpha-beta 剪枝

可以改变要检查的博弈树的大小来改进搜索。

按 pl 走。

### 蒙特卡洛搜索

决策树的启发式搜索算法

没有评估函数？随机行动模拟游戏，在游戏最终得分，保持胜利记录

#### 选择

递归应用策略，直到找到叶节点。

![image-20210913190647685](C:\Users\surafce book2\AppData\Roaming\Typora\typora-user-images\image-20210913190647685.png)

对于被检查的局面而言，他可能有三种可能：

1. 该节点所有可行动作都已经被拓展过

2. 该节点有可行动作还未被拓展过

3. **这个节点游戏已经结束了**(例如已经连成五子的五子棋局面)

对于这三种可能：

1. 如果所有可行动作都已经被拓展过了，那么我们将使用UCB公式计算该节点所有子节点的UCB值，并找到值最大的一个子节点继续检查。反复向下迭代。
2. 如果被检查的局面依然存在没有被拓展的子节点(例如说某节点有20个可行动作，但是在搜索树中才创建了19个子节点)，那么我们认为这个节点就是本次迭代的的目标节点N，并找出N还未被拓展的动作A。执行步骤[2]
3. 如果被检查到的节点是一个游戏已经结束的节点。那么从该节点直接执行步骤{4]。

#### 拓展

进行一次模拟游戏

![image-20210913190945917](C:\Users\surafce book2\AppData\Roaming\Typora\typora-user-images\image-20210913190945917.png)

在选择阶段结束时候，我们查找到了一个最迫切被拓展的节点N，以及他一个尚未拓展的动作A。在搜索树中创建一个新的节点Nn作为N的一个新子节点。Nn的局面就是节点N在执行了动作A之后的局面。

#### 模拟

![image-20210913191117255](C:\Users\surafce book2\AppData\Roaming\Typora\typora-user-images\image-20210913191117255.png)

为了让Nn得到一个初始的评分。我们从Nn开始，让游戏随机进行，直到得到一个游戏结局，这个结局将作为Nn的初始评分。一般使用胜利/失败来作为评分，只有1或者0。

#### 反向传播

![image-20210913191126689](C:\Users\surafce book2\AppData\Roaming\Typora\typora-user-images\image-20210913191126689.png)

在Nn的模拟结束之后，它的父节点N以及从根节点到N的路径上的所有节点都会根据本次模拟的结果来添加自己的累计评分。如果在[1]的选择中直接发现了一个游戏结局的话，根据该结局来更新评分。每一次迭代都会拓展搜索树，随着迭代次数的增加，搜索树的规模也不断增加。当到了一定的迭代次数或者时间之后结束，选择根节点下最好的子节点作为本次决策的结果。

小结一下：

- 选择（Selection）：从根节点*R*开始，连续向下选择子节点至叶子节点*L*。下文将给出一种选择子节点的方法，让[游戏树](https://zh.wikipedia.org/wiki/遊戲樹)向最优的方向扩展，这是蒙特卡洛树搜索的精要所在。
- 扩展（Expansion）：除非任意一方的输赢使得游戏在L结束，否则创建一个或多个子节点并选取其中一个节点*C*。
- 仿真（Simulation）：在从节点*C*开始，用随机策略进行游戏，又称为playout或者rollout。
- 反向传播（Backpropagation）：使用随机游戏的结果，更新从*C*到*R*的路径上的节点信息。

#### UCT算法：树内选择策略

选择子结点的主要困难是：在较高平均胜率的移动后，在对深层次变型的利用和对少数模拟移动的探索，这二者中保持某种平衡。
$$
\frac{w_i}{n_i}+c\sqrt\frac{\ln t}{n_i}
$$
式中：

- $w_i$代表第$i$次移动后取胜的次数；
- $n_i$代表第{\displaystyle i}![i](https://wikimedia.org/api/rest_v1/media/math/render/svg/add78d8608ad86e54951b8c8bd6c8d8416533d20)次移动后仿真的次数；
- $c$为探索参数—理论上等于$\sqrt 2$；在实际中通常可凭经验选择；
- $t$代表仿真总次数，等于所有$n_i$的和。

## 增强学习

### Q学习

[Q学习 - 维基百科，自由的百科全书 (wikipedia.org)](https://zh.wikipedia.org/wiki/Q学习)

*Q*-学习最简单的实现方式就是将奖励值存储在一个表格（Q-table）中，但是这种方式受限于状态和动作空间的数目。
$$
Q(state,action) = R(state,action) + \gamma \max(Q(next\ state,all\ actions))
$$
式中Q为Q表格，R为初始reward矩阵。

## 贝叶斯学习

### 贝叶斯公式

$$
p(h|D)=\frac{p(D|h)p(h)}{p(D)}
$$

D:训练数据

h:假设

$p(h|D)$:给定训练数据下，假设h的条件概率

$p(D)$:数据集D的先验概率

### 最大似然估计

估计的参数是有但不知道是多少的，那我就假设这个概率分布，求这个参数。

似然函数：
$$
l(\theta) = p(x_1,x_2,\dots,x_N|\theta)=\prod_{k=1}^Np(x_k|\theta)
$$
最大似然估计：
$$
\hat \theta_{ML}=\arg\max_\theta l(\theta)
$$
求法：
$$
\nabla_\theta l(\theta)|_{\hat\theta_{ML}}=\sum_{k=1}^N\nabla_\theta p(x_k|\theta)|_{\hat\theta_{ML}}
$$

### 暴力 MAP 学习器

对 $H$ 中每个 $h$ ，计算：
$$
P(h|D) = \frac{P(D|h)P(h)}{P(D)}
$$
输出：
$$
h_{MAP}=\arg\max_{h\in H} P(h|D)
$$
提供了判断一个学习算法学习性能的标准

前提：训练数据 $D$ 无噪声，假设概率未知，$p(h) = \frac 1 {|H|}$，$p(D|h) = [d_i = h(x_i)]$。

考察后验概率：不一致则为 $0$ ，若一致则为：$P(h|D)=\frac{\frac{1}{|H|}}{P(D)}=\frac{\frac{1}{|H|}}{\frac{|VS_{H,D}|}{|H|}}=\frac 1 {|VS_{H,D}|}$，式中$VS_{H,D}$ 表示 $H$ 中与 $D$ 一致的假设空间。

本质：犯过错的就剔除。

###  朴素贝叶斯

### 极大似然和最小平方误差假设

## L4

### 决策树

#### 决策树学习

##### 信息增益

信息熵是度量样本集合纯度最常用的指标。
$$
\mathrm{Ent}(D)=-\sum_{k=1}^{|\mathcal Y|}p_k\log_2p_k
$$
$\mathrm{Ent}(D)$值越小，则$D$的纯度越高。

假设离散属性$a$有$V$个可能取值$\{a^1,a^2,\dots,a^V\}$，若使用$a$对样本集$D$进行划分，就会产生$V$个分支节点，第$v$个分支节点包含$D$中所有属性值为$a^v$的样本，记为$D^v$，则可以计算$D^v$的信息熵，再给出权重$|D^v|/|D|$，则有信息增益：
$$
\mathrm {Gain}(D,a) = \mathrm{Ent}(D)-\sum_{v=1}^V\frac{|D^v|}{|D|}\mathrm{Ent}(D^v)
$$
这里的概率基于最后的结果。

选择最大的信息增益，作为划分属性。

## 线性判别函数

决策面函数：可能很复杂，用线性分类器搞。

### 线性判别函数

$g(x)=w^Tx$

1. 收集样本$K=\{x_1,x_2,\dots,x_N\}$
2. 按需要确定准则函数，反应分类器性能$J(K,w)$
3. 用优化技术求准则函数极值解$w^*$，从而确定判别函数，完成设计

$$
w^*=\arg \max_w J(K,w)
$$

一般形式：$g(x)=w^Tx+w_0$

### Fisher线性判别

线性判别函数$g(x)=w^Tx$

- 样本向量$x$各分量的线性加权
- 样本向量$x$与权向量$w$点积
- 如果$||w||=1$，可看作投影

Fisher准则：找到最合适的投影轴，使两类样本在该轴上投影之间的距离尽可能远，而每类样本投影尽可能紧凑，从而使分类效果最佳

### 感知器准测

#### 线性可分性

训练样本集中的两类样本在特征空间可以用一个线性分界面正确分开。

在该条件下，有：
$$
if\ y\in\omega_1,w^Ty>0\\
if\ y\in\omega_2,w^Ty<0\\
$$
首先规范化：

如果$y\in\omega_2$，$y^{'} = -y$，其余不变。

则编程

### 支持向量机

## L5

### 主成分分析

人脸识别领域

模式识别系统的基本组成

特征提取：输入信号中提取有效特征。重要特点——降维，简化了模式识别。

人脸图像的特征提取：如active shape model

主成分分析：利用线性映射进行数据降维的方法，去除数据的**相关性**，且最大限度保持原始数据的**方差信息**。

意义：在同样的精度下，存储量最小。（降低数据的冗余）方差越大，数据分布越分散，越能保持原始空间中的距离信息

#### 线性映射的意义

$P$维向量$x$到一维向量$F$的一个线性映射表示为：
$$
F=\sum_{i=1}^Pu_iX_i=u^TX
$$
相当于加权求和，每一组权重系数为一个主成分。

去除数据的相关性，只需让各个主成份正交，正交的基构成的空间称之为子空间。

#### 基于PCA特征提取的基本思想

试图在数据信息丢失最少的原则下，对高维空间数据进行降维。

进行PCA的目的之一是希望用尽可能少的主成分代替原来的$P$维向量。到底选多少？实际生活选择95%的信息量作为依据。

 ## L6

### Adaboost

